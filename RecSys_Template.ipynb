{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **AI Society Final Project: ASU Event RecSys**\n",
        "\n"
      ],
      "metadata": {
        "id": "zst68rQHF7zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Jupyter Notebooks and Python\n",
        "For workshops, we typically use **Google Colab**, a service that allows you to run python code in a nice containerized environment. It even provides free GPU/TPU runtimes!\n",
        "___\n",
        "\n",
        "In Google Colab, you write code using **Jupyter notebooks**. Notebooks are comprised of text and code cells, which can be run by hitting `Shift + Enter`. For your convenience, here are a few more nifty keyboard shortcuts:\n",
        "\n",
        "* `b`: New cell below\n",
        "* `a`: New cell above\n",
        "\n",
        "\n",
        "## Hardware Needed:\n",
        "Any computer with access to the internet and web browser\n",
        "\n",
        "* üëâüèªLink to Dataset:\n",
        "https://drive.google.com/file/d/1UeoAi3Aab-0Gx-B62aGqzeL3GY6SkQBE/view?usp=sharing"
      ],
      "metadata": {
        "id": "6DMqOx8OAr7g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrdgnBpAYpU3"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's import the data here.\n",
        "data ="
      ],
      "metadata": {
        "id": "wMUIeDXMZnfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset includes event details like name, description, location, host organization, and perks. Let's preprocess this data to make it suitable for recommendations."
      ],
      "metadata": {
        "id": "zcI3wMqxHC4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's print a few entries to see if data is properly loaded.\n"
      ],
      "metadata": {
        "id": "AeeLNtzUEDRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Exploring the Data**\n",
        "Here, we‚Äôre answering questions like:\n",
        "\n",
        "How many rows and columns does this data have?\n",
        "Are there missing values?\n",
        "What are the ranges of numerical data?"
      ],
      "metadata": {
        "id": "Z6tzfsuzNNNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's find out all the columns/features.\n"
      ],
      "metadata": {
        "id": "X8cjCTW7GSTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the dimentions of the dataset.\n"
      ],
      "metadata": {
        "id": "WVxsVHk4kxK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relevant features for output. (From consumers point of view)\n",
        "`['event_name', 'datetime', 'description', 'host_org', 'event_perks', 'location']`"
      ],
      "metadata": {
        "id": "b6YiSdGF8z8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create another dataset named df for recommendation output.\n"
      ],
      "metadata": {
        "id": "trAHgzNjk3rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['event_name'].value_counts().head(10).plot(kind='bar', title='Top Events')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "btVr3XgMHslI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "KL5Vf-N2GueH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill the na values with unknown in host_org, event_perks features in df dataframe (for df dataframe)\n",
        "df['host_org']\n",
        "df['event_perks']"
      ],
      "metadata": {
        "id": "sUehHj76mmrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For data dataframe let's fill na with nothing to for making it string type.\n",
        "data['host_org'] = data['host_org'].fillna('')\n",
        "data.event_perks = data.event_perks.fillna('')\n",
        "data.categories = data.categories.fillna('')"
      ],
      "metadata": {
        "id": "2HBUmnRrZ0qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a feature with all the essential information.\n"
      ],
      "metadata": {
        "id": "a2Z8lAPvoGMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing text preprocessing libraries.\n",
        "import re\n",
        "import string\n",
        "!pip install contractions\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "hxjr0PJRaXQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(data):\n",
        "\n",
        "    # Convert to lowercase\n",
        "    if isinstance(data, pd.Series):\n",
        "        data = data.astype(str).apply(lambda x: x.lower())\n",
        "    else:\n",
        "        data = data.lower()\n",
        "\n",
        "    # Remove HTML tags\n",
        "    data = re.sub(r'<.*?>', '', data)\n",
        "\n",
        "    # Remove URLs\n",
        "    data = re.sub(r'https?://[^\\s]+', '', data)\n",
        "\n",
        "    # Remove mentions\n",
        "    data = re.sub(r'@\\w+', '', data)\n",
        "\n",
        "    # Remove hashtags\n",
        "    data = re.sub(r'#\\w+', '', data)\n",
        "\n",
        "    # Remove special characters and punctuation\n",
        "    data = re.sub(r'[^a-zA-Z0-9\\s]', '', data)\n",
        "\n",
        "    # Remove punctuation\n",
        "    data = data.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove digits\n",
        "    data = ''.join([i for i in data if not i.isdigit()])\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    data = re.sub(r'\\s+', ' ', data.strip())\n",
        "\n",
        "    # Performing contractions\n",
        "    data = contractions.fix(data)\n",
        "\n",
        "    # Remove stop words using NLTK\n",
        "    stop = nltk.corpus.stopwords.words('english')\n",
        "    data = ' '.join([x for x in data.split() if x not in (stop)])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "5m1ZZEJGbwpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply this preprocess_text function to out information feature.\n"
      ],
      "metadata": {
        "id": "B524-3Kqbz1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TF-IDF Vectorization**\n",
        "\n",
        "*In this section, we will use the `TfidfVectorizer` from the `sklearn` library to convert our preprocessed text data into TF-IDF features. This method helps in representing the importance of words in the documents relative to the entire corpus.*\n",
        "\n",
        "## **What is TF-IDF?**\n",
        "\n",
        "*TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure used to evaluate the importance of a word in a document relative to a collection of documents (corpus). The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus.*\n",
        "\n",
        "### **Formula**\n",
        "\n",
        "- **TF (Term Frequency)**:\n",
        "  TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
        "\n",
        "- **IDF (Inverse Document Frequency)**:\n",
        "  IDF(t) = log(Total number of documents / Number of documents with term t in it)\n",
        "\n",
        "- **TF-IDF**:\n",
        "  TF-IDF(t) = TF(t) * IDF(t)\n",
        "\n",
        "## **Using TfidfVectorizer**\n",
        "\n",
        "*We use the `TfidfVectorizer` to transform the processed text into a TF-IDF matrix, which we then convert into a DataFrame.*"
      ],
      "metadata": {
        "id": "2jifKrwX4RKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommned(user_input):\n",
        "\n",
        "  # Preprocess user input\n",
        "\n",
        "\n",
        "  # Combining ifidf from data.\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  vectorizer = TfidfVectorizer(max_features=10000)\n",
        "\n",
        "  # Fit the vectorizer on the combined text data\n",
        "\n",
        "\n",
        "  # Transform the user input\n",
        "\n",
        "\n",
        "  # Transform the text data\n",
        "\n",
        "\n",
        "  # Calculate cosine similarity\n",
        "  from sklearn.metrics.pairwise import cosine_similarity\n",
        "  cosine_sim = cosine_similarity(user_ifidf, df_tfidf)\n",
        "\n",
        "  # Get top 5 recommendations\n",
        "  top_indices = cosine_sim.argsort().flatten()[-5:][::-1]\n",
        "  recommendations =\n",
        "  return recommendations"
      ],
      "metadata": {
        "id": "psHqQcyGcfH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally finished! Let's find some interesting events."
      ],
      "metadata": {
        "id": "Os72UiMrpcWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommned('I like music, free food, and networking')"
      ],
      "metadata": {
        "id": "wxs0d67nk9Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try another prompt: `As a business student, I‚Äôm interested in networking events, resume workshops, and opportunities to connect with recruiters. Any weekday events that offer chances to meet professionals or get career tips?`"
      ],
      "metadata": {
        "id": "nWDT9uKM6vAr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qtyTTWL60hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try another prompt: `I‚Äôm a computer science student and like tech events and workshops where I can learn new skills and meet people in my field. Are there any good events on campus?\"`"
      ],
      "metadata": {
        "id": "oNI0oPhO7GZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmCmhyIe7RfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------\n",
        "**You can try another prompts of your choice and play with the model**"
      ],
      "metadata": {
        "id": "hn_nVMZt7amx"
      }
    }
  ]
}